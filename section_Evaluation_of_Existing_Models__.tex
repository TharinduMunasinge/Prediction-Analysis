\section{Evaluation of Existing Models}

In this analysis, we quantitatively and qualitatively analyze the ability of several prediction techniques to learn from the current workload history, and then predict future workload while the workload itself is evolving, similar to what happens in case of an auto scaler in operation. We simulated an online training scenario by streaming data points of the workload time series one at a time to each prediction technique. We then plotted the one-step lookahead predictions from the resulting prediction technique at each stage, against the real data points. For evaluation purpose, we used the forecast package in R \cite{forecastPackage} which contains time series datasets in different domains with typical patterns like trends, cycles and seasonality factors.

Section 3.1 presents the workloads used for the evaluation while Section 3.2 describes the time series prediction techniques selected for the evaluation. Simulation setup is presented in Section 3.3. Evaluation of selected techniques under selected workloads is presented in Section 3.4.

\subsection{Datasets}
As the objective of this experiment is to identify how well an individual prediction method can predict future values by only considering the past history, we used several publicly available datasets with predictable patterns from the R forecast package, some of which are not directly related to cloud workloads. Selection of multiple datasets enables us to evaluate the time series prediction techniques under several probable workload patterns. Neverthless, the experimental results in Section 5, where we compare the performance of the proposed ensemble technique vs. existing methods, are based only on two real-world cloud workloads and the Google cluster dataset, in addition to those found in the forecast package.

Following datasets from the R forecast package is selected for the evaluation:
\begin{itemize}
\item euretail -- Quarterly retail trade index in the Euro area (17 countries) from 1996 - 2011, covering wholesale and retail trade, and repair of motor vehicles and motorcycles (Index: 2005 = 100).
\item sunspotarea -- Annual averages of the daily sunspot areas (in units of millionths of a hemisphere) for the full sun.
\item oil -- Annual oil production (millions of tonnes) from Saudi Arabia between 1965 - 2010.
\end{itemize}

In addition, as a representative of real world workloads, we have used a CPU trace obtained from a dedicated standalone server from a private cloud. The server has a Linux-based operating system and is equipped with four Quad-Core AMD Opteron CPUs and 16 GB of RAM.

\subsection{Time Series Forecasting Techniques}
We chose three widely used prediction methods from literature, namely ARIMA, neural network, and exponential models, as well as the existing workload prediction technique in Apache Stratos.

\subsubsection{ARIMA}
Autoregressive Integrated Moving Average (ARIMA) model combines two models called autoregression (of order $p$) and moving average (of order $q$).

\noindent
\textit{Autoregression Model AR($p$) --}
In an autoregression model, the variable of interest is forecast using a linear combination of past values of the variable. The term autoregression indicates that it is a regression of the variable against itself. Thus, an autoregressive model of order $p$ can be written as:
	$$x_t = c + \phi_1x_{ t-1} + \phi_2x_{t-2} +...+ \phi_px_{t-p} + e_{t}$$
where $c$ is a constant and $e_t$ is white noise (list of Symbols are given in Table 1). Autoregressive models are typically restricted to stationary data, and then some constraints are applied on the values of the parameters \cite{Forecasting_OTexts} as follows:

    For an AR(1) model: $-1 < \phi_{1} < 1$
    For an AR(2) model: $-1 < \phi_{2} < 1$ ,$\phi_{2}+ \phi_{1} < 1$ , $\phi_{2} - \phi_{1} < 1$

\noindent
\textit{Moving Average Model MA($q$) --}
This model uses past forecast errors in a regression-like model.
	$$x_t = c + \theta_1e_{ t-1} + \theta_2e_{t-2} +...+ \theta_qe_{t-q}$$
where $e_t$ is white noise. $x_t$ can be thought of as a weighted moving average of the last few forecast errors. 
By combining differencing with autoregression and a moving average model, non-seasonal ARIMA model can be obtained. The full model can be written as:

\begin{equation}
\begin{split}
{x}'_t = c+ \phi_1{x}'_{ t-1} + \phi_2{x}'_{t-2} +...+ \phi_p{x}'_{t-p}\\ + e_{t} + \theta_1e_{ t-1} + \theta_2e_{t-2} +...+ \theta_qe_{t-q}
\end{split}
\end{equation}


The \textit{predictors} on the right hand side include both the lagged values of $X_t$ and lagged errors. This is called an ARIMA($p$, $d$, $q$) model, where $p$ and $q$ are the orders of the autoregressive and moving average parts respectively, and $d$ is the degree of first differencing involved.

\subsubsection{Neural Networks}
Artificial Neural Networks (ANNs) are a class of nonlinear, and data-driven models which are inspired by the working mechanism of human brain. In the domain of time series forecasting, neural network is an excellent alternative for existing statistical models which require some assumptions to be satisfied in the time series. Ability of modeling nonlinear relationships is the major advantage in neural networks. Depending on the topology of the network there are various types of neural networks which are suitable for various machine learning tasks. Auto regressive feed forward neural networks \cite{Forecasting_OTexts} are the specialized neural networks in the time series forecasting domain. They consist of a feed forward structure of three types of layers, an input layer, one or more hidden layer, and an output layer. Each layer consists with nodes, which connected to those in the immediate next layer by acyclic links which have associated weights. In auto regressive neural networks, lagged values of the time series (input window) are injected as the inputs and train the weights of the model to forecast for a given time horizon by using the past history of the dataset. 

\subsubsection{Exponential Model}
Several selected versions of exponential models are presented next.

\noindent
\textit{Exponential Weighted Moving Average (EWMA)} --
In EWMA methods, forecasts are calculated using weighted averages where the weights decrease exponentially as the observations come from further in the past. The smallest weights are associated with the oldest observations \cite{Forecasting_OTexts}, \cite{STAT510}, \cite{StatSoft}. Exponential smoothing can be indicated by the following equation:

	$$\hat{x}_{t+1|t}=\alpha x_t +\alpha(1-\alpha)\hat{x}_{t|t-1}$$
	$$\hat{x}_{t+1|t}=\alpha x_t +\alpha(1-\alpha)x_{t-1}+\alpha(1-\alpha)^2x_{t-2}+...$$
where $0\leq \alpha \leq 1$ is the smoothing parameter. $\hat{x}_{t+1|t}$, the one-step-ahead forecast for time $t+1$, is a weighted average of all the observations in the series $x_1$, ..., $x_t$. The rate at which the weights decrease is controlled by the parameter $\alpha$. If $\alpha$ is small (i.e., close to 0), more weight is given to observations from the distant past. If $\alpha$ is large (i.e., close to 1), more weight is given to the more recent observations. This method is suitable for forecasting data with no trend or seasonal patterns.

Following variations of basic exponential smoothing are suitable for forecasting time series with various characteristics \cite{Forecasting_OTexts}:

\begin{itemize}
\item \textit{Double Exponential Smoothing} -- Applicable to a time-series with a linear trend.
\item \textit{Triple exponential smoothing} -- Applicable to a time-series with a trend and seasonality.
\item \textit{Holt's Linear Trend Model} -- Extended simple exponential smoothing to allow forecasting of data with a trend.
\item \textit{Exponential Trend Model} -- Applicable when the trend in the forecast function is can be exponential rather than linear.
\item \textit{Damped Trend method} -- Dampens the trend to a flat line some time in the future to model the general nature of practical time series.
\item \textit{Holt-Winters Seasonal method} -- Applicable to a time series with adaptive or multiplicative trends and seasonality.
\end{itemize}

\subsubsection{Prediction method in Apache Stratos}
Apache Stratos is an open source PaaS framework where a user can build a PaaS system on top of an existing IaaS cloud. The auto scaling solution in Stratos uses a workload demand prediction method which can be explained using the motion equation in physics. The method calculates one lookahead prediction using the workload demand in the last period as follows \cite{StratosModel}:
\begin{eqnarray}
S_{t+h|t} = u_{t}h+ \frac{1}{2} a_{t}h^2 \\
\hat{x}_{t+h}=avg(x)_{t} + S_{t+h|t} 
\end{eqnarray}

\begin{table}[]
\centering
\caption{List of Symbols in Stratos Prediction Model}
\begin{tabular}{ll}
\hline
Parameter       & Description                                                                     \\ \hline
$S_{t+h|t}$     & Predicted change of workload for time $(t+h)$ based on interval $t$ \\
$x$             & Workload metric(s)                                                                \\ \hline
$\hat{x}_{t+h}$ & Predicted workload metrics for time $t+h$                                       \\ \hline
$u_{t}$         & First derivative of the workload metrics within the $t$-th interval           \\ \hline
$a_{t}$         & Second derivative of the workload metrics within the $t$-th interval          \\ \hline
$h$             & Time horizon                    
\end{tabular}
\end{table}

\subsection{Time Series Forecasting Library}

We used the following time series forecasting models in R forecast package \cite{forecastPackage} to implement each of the selected forecasting solution:

\noindent
$auto.arima()$ -- Finds out the best fitted ARIMA model and approximates the model coefficients by minimizing the past forecast error \cite{Forecasting_OTexts}.

\noindent
$ets()$ -- Finds out the best fitted exponential model among the family of exponential models (simple exponential smoothing, Holt's linear trend, exponential trend, and Holt-Winters seasonal method) automatically and calculates the model coefficients by reducing the past forecast error \cite{Forecasting_OTexts}.

\noindent
$nnetar()$ -- Feed-forward neural networks with a single hidden layer and lagged inputs for forecasting univariate time series.