\section{Evaluation of Existing Models}

In this analysis we wanted to qualitatively analyze the ability of individual prediction techniques to learn from current workload history and predict the time series while time series data is evolving periodically, similar to what happens in case of an autonomous auto-scaler in operation. We simulated an online training scenario by streaming data points of the time series one at a time to each method and plotted the one-step lookahead predictions from the resulting models at each stage, against the real data points. For evaluation purpose we used the forecast package in R \cite{forecastPackage} in which there are time series datasets in different domains with typical patterns like trends, cycles and seasonality factors.

\subsection{Datasets}
Since the objective of this experiment is to identify how well an individual prediction method can predict future values by only considering the past history, we tried several publicly available datasets in the forecast package with predictable patterns, even when they are not directly related to cloud workloads. Neverthless, the experimental results elaborated in Section 5, in which we  compare and contrast the performance of the proposed method vs existing methods, are based on two real-world cloud workloads and the Google cluster dataset, in addition to those found in the forecast package.

\begin{itemize}
\item airmiles : The revenue passenger miles flown by commercial airlines in the United States for each year from 1937 to 1960
\item euretial: Quarterly retail trade index in the Euro area (17 countries), 1996-2011, covering wholesale and retail trade, and repair of motor vehicles and motorcycles. (Index: 2005 = 100)
\item sunspotarea: Annual averages of the daily sunspot areas (in units of millionths of a hemisphere) for the full sun. Sunspots are magnetic regions that appear as dark spots on the surface of the sun. The Royal Greenwich Observatory compiled daily sunspot observations from May 1874 to 1976. Later data are from the US Air Force and the US National Oceanic and Atmospheric Administration
\item oil: Annual oil production (millions of tonnes), Saudi Arabia, 1965-2010
\end{itemize}

\subsection{Time series forecasting techniques}
We chose three widely used prediction methods from literature, ARIMA, neural network and exponential models, and the existing workload prediction technique in Stratos.

\subsubsection{ARIMA}
This model combines two models called auto regression (of order $p$) and moving average (of order $q$) .\\

Autoregression model ($p$): 
In an autoregression model, the variable of interest is forecasted using a linear combination of past values of the variable. The term autoregression indicates that it is a regression of the variable against itself. Thus an autoregressive model of order p can be written as
	$$x_t = c + \phi_1x_{ t-1} + \phi_2x_{t-2} +...+ \phi_px_{t-p} + e_{t}$$
where c is a constant and et is white noise. Autoregressive models are normally restricted to stationary data, and then some constraints on the values of the parameters are required [16]. \\
For an AR(1) model: $-1 < \phi_{1} < 1$ \\
For an AR(2) model: $-1 < \phi_{2} < 1$ ,$\phi_{2}+ \phi_{1} < 1$ , $\phi_{2} - \phi_{1} < 1$ \\
Moving average model MA(q):  
Moving average model uses past forecast errors in a regression-like model.
	$$x_t =  c + \theta_1e_{ t-1} + \theta_2e_{t-2} +...+ \theta_qe_{t-q}$$
where $e_t$ is white noise. $x_t$ can be thought of as a weighted moving average of the past few forecast errors. However, moving average models should not be confused with moving average smoothing. The former is used for forecasting future values while the latter is used for estimating the trend-cycle of past values.
By combining the differencing with autoregression and a moving average model, we obtain a non-seasonal ARIMA model. ARIMA is an acronym for AutoRegressive Integrated Moving Average. The full model can be written as:

	$${x}'_t = c + \phi_1{x}'_{ t-1} + \phi_2{x}'_{t-2} +...+ \phi_p{x}'_{t-p} + e_{t} + \theta_1e_{ t-1} + \theta_2e_{t-2} +...+ \theta_qe_{t-q}$$
The “predictors” on the right hand side include both lagged values of Xt and lagged errors. This is called this an ARIMA(p, d, q) model, where p and q are the orders of the autoregressive and moving average parts respectively, and d is the degree of first differencing involved.


\subsubsection{Neural Network}
ANNs are a class of nonlinear, nonparametric, datadriven and self-adaptive models, originally inspired by the
intelligent working mechanism of human brains . Over the years, ANNs are used as excellent alternative to the common statistical models for time series forecasting. The most popular ANN architectures in forecasting domain are the Multilayer Perceptrons (MLPs). They consist of a feedforward structure of three layers, viz. an input layer, one or more hidden layer and an output layer. The nodes in each layer are connected to those in the immediate next layer by acyclic links . Single hidden layer is sufficient for most applications. It is often customary to use the notation (p, h, q) for referring an ANN with p input, h hidden and q output nodes.

\subsubsection{Exponential Model}
Exponential weighted moving average: In exponential weighted moving average methods, forecasts are calculated using weighted averages where the weights decrease exponentially as observations come from further in the past. The smallest weights are associated with the oldest observations [16][24][25].
Simple exponential smoothing:
	$$X_{t+1}=\alpha x_t +\alpha(1-\alpha)X_{t-1}$$
	$$X_{t+1}=\alpha x_t +\alpha(1-\alpha)x_{t-1}+\alpha(1-\alpha)^2x_{t-2}+\alpha(1-\alpha)^3x_{t-3}+...$$
where $0\leq \alpha \leq 1$ is the smoothing parameter. The one-step-ahead forecast for time $t+1$ is a weighted average of all the observations in the series $x_1, …, x_t$. The rate at which the weights decrease is controlled by the parameter α. If $\alpha$ is small (i.e. close to 0), more weight is given to observations from the distant past. If $\alpha$ is large (i.e., close to 1), more weight is given to the more recent observations. This method is suitable for forecasting data with no trend or seasonal patterns.

Double exponential smoothing: Double smoothing can be applied to a time-series with an existing linear trend. This can be derived by applying exponential smoothing to the data already smoothed using simple exponential smoothing. There is a need to add a second smoothing constant to account for trend.
Triple exponential smoothing: Triple smoothing can be applied to a time-series with existing trend and seasonality. This can be derived by applying exponential smoothing to the data already smoothed using double exponential smoothing.


\subsubsection{Prediction method in Apache Stratos}



\subsection{implementation of methods}
For this evaluation we have used the implementations of the Forecast pacakge \cite{forecastPackage}
ARIMA: According to <<ROBIN>> auto.arima()  find out the best fitted ARIMA model and approximated the model coeffficents in by minimizing the error<<<BESPECIFIC >>> [https://www.otexts.org/fpp/8/7]

Ets: Model the data with best fitted exponential model [https://www.otexts.org/fpp/7/7]
    \cite{Wagner_2011}
	Nnetar: [https://www.otexts.org/fpp/9/3]
