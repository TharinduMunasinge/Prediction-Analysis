\section{Introduction}

Cloud computing has already gained ground with advantages like scalability, high availability and on-demand resource provisioning. According to the NIST definition \cite{Mell_2011}, cloud computing refers to the delivery of computing resources, such as networks, servers, storage, applications and platforms, over the network based on user demand. Based on the definition, it is evident that elasticity is a major requirement of any cloud platform, which is often achieved via an auto scaling process. Auto scaling refers to the dynamic allocation and deallocation of resources for a cloud application, in order to optimize its resource utilization while minimizing the cost as well as achieving the desired Quality of Service (QoS) and availability goals \cite{Roy_2011} \cite{Armbrust_2010}.

Autoscaling can be achieved via reactive as well as proactive approaches. In reactive, threshold based auto-scaling, users have to specify thresholds for workload metrics, and scaling would occur only after such thresholds are exceeded \cite{Lorido_Botran_2014}. In this approach, even though it is desirable to maintain high thresholds which would result in higher levels of resource utilization, thresholds should be sufficiently small to compensate for delays in formulating and executing scaling action. Although this seems to be the most customizable approach from the userâ€™s perspective, it has several weaknesses \cite{Alipour:2014:AAI:2735522.2735532} such as the inability to adapt to workload patterns (e.g., thrashing during load fluctuations), low resource utilization and higher cost under smaller thresholds, and the risk of service degradation under larger thresholds and rapidly increasing workloads. Coming up with an optimum threshold in a reactive auto scaling system is nontrivial and it requires prior user expertise (e.g., of traffic patterns and IaaS/PaaS parameters like pricing models and packages) for composing effective thresholds that can carry out scaling efficiently.

In the proactive approach, resource requirements for the future time horizon are forecast based on the demand history. With accurate predictions, an application can take early scaling decisions so that when the workload reach a particular level, the required resources would have already been allocated. As a result, resource utilization can be safely increased to a maximum level. However, the reliability of such an approach depends mainly on the accuracy of the predicted values. Since we forecast the future workload requirement (e.g., memory consumption, CPU utilization, network request count) from historical data of the respective measures, time series forecasting methods are applicable for this requirement.

We have identified several challenges specific to workload prediction for auto scaling:
\begin{itemize}
\item A PaaS system can have different applications with different workload patterns, so that the workload prediction model should not tend to get overfitted to a specific workload pattern.
\item The workload dataset grows continuously with time, so that the predictive model should evolve and continuously learn the latest workload characteristic. 
\item The workload predictor should be able to produce results within a bounded time period.
\item Given that the time horizon for the prediction should be chosen based on the physical constraints like uptime and graceful shutdown time of VMs, the predictor should be able to produce sufficiently accurate results over a sufficiently large horizon.
\end{itemize}

The objective of this work is to come up with a prediction method that can be trained real-time in order to capture the latest trends and provide sufficiently accurate results for drastically different workload patterns. First we have evaluated the ability of individual models to produce accurate real-time predictions against evolving datasets. In this evaluation we have tested time series forecasting methods including statistical methods like ARIMA and exponential model, machine learning models like neural networks, and a prediction method used in Apache Stratos, an open source PaaS framework. Next we have implemented our proposed ensemble technique which combines results from neural network, ARIMA and exponential models, and tested it against three publicly available datasets, two real-world cloud workload datasets, and the Google cluster dataset. According to experimental results, our proposed solution outperforms each of the tested individual methods, and two other ensemble techniques as well.

The rest of the paper is structured as follows: Section 2 outlines existing work on cloud workload prediction techniques and their limitations. Section 3 describes and evaluates existing time series forecasting techniques while exploring their ability to provide accurate predictions on publicly available datasets with predictable patterns under real-time training scenarios. Section 4 introduces and explains our ensemble technique and prediction algorithm. Section 5 presents the results of the tests performed, and Section 6 consists of the concluding remarks.