\section{Introdution}

Cloud computing is no longer the next revolution, it has already gain the ground with advantages like scalability, high availability and on-demand resource provisioning. According to the NIST definition \cite{Mell_2011} ,  cloud computing refers to the delivery of computing resources like networks, servers, storage, application and platform over the network based on the user’s demand. Even from the definition it’s clear that Elasticity is a major feature in cloud platform which is often achieved via an auto-scaling process. Auto scaling refers to  dynamically allocates and deallocates resources for a cloud application to optimize its resource utilization while minimizing the cost as well as achieving the desired Quality of Service (QoS) and availability goals.\cite{Roy_2011}\cite{Armbrust_2010}.

Autoscaling can be achieved  reactive based approach or proactive based approach. In reactive, threshold based auto-scaling, users have to specify the thresholds for workloads  and scaling would occur only after the thresholds are exceeded\cite{Lorido_Botran_2014}. In reactive-threshold autoscaling, eventhough its desirable to have high thresholds which makes the resource utilization higher, thresholds should be sufficiently small to compensate for the delay in taking the scaling action[REVISE] .    Although this seems to be the most customizable approach from the user’s perspective, it has several weaknesses \cite{Alipour:2014:AAI:2735522.2735532} like inability to adapt to workload patterns (e.g., thrashing during load fluctuations),low resource utilization and higher cost under the smaller thresholds and having a larger threshold introduce the risk of service degradation at rapidly increasing workloads. To come up with a optimum thresholds in an reactive autoscaling system is non trivial and it requires prior user expertise (e.g., of traffic patterns and IaaS/PaaS parameters like pricing models and packages) for composing effective thresholds that can carry out scaling efficiently.

In proactive approach resource requirement for the future time horizon is forecast by based on demand history.With accurate predictions, an application can take early scaling decisions so that when the workload demand reach to particular value, required resources will already be allocated. So that the resource  utilization can be increased to a maximum level. But the reliability of such approach mainly depends on the accuracy of the predicted values.Since we forecast the future workload require (Eg. Memroy consumption, Cpu utilization, Network request count) from the past history of the same measure , time series forecasting methods can be used for this calculation. 
We have identified several challenges specific to workload prediction for auto scaling.
\begin{itemize}
\item PaaS system can have different applications with different workload patterns, so that the workload prediction model should not be over fitted to a specific workload pattern.
\item Workload data set continuously grow with time so that the predictive model should be evolved and continuously learn the workload characteristic. 
\item Workload predictor should be able to give results within a bounded time period.
\item Give that the  time horizon for the prediction should be chosen based on the physical constraints like VM uptime and gracefully shutting down time, predictor should be able to give sufficiently accurate results in longer horizon.
\end{itemize}

The objective of this work is to come up with a prediction method that can be trained real-time in each iteration to capture the latest trends and provides sufficiently accurate results over drastically different workload patterns. First we evaluated the ability of individual models to give accurate answers in real-time predictions on evolving dataset. In that experiment we tested time series forecasting methods including both statistical methods like ARIMA and Exponential Model, machine learning models like neural network and a prediction method used in Apache Stratos an open source Platform as a service framework. Then we have implemented our proposed ensemble technique combining the results from neural network, AEIMA and exponential model, and tested on three publicly available datasets, two real-world cloud workload dataset and Google cluster dataset. According to the experimental results our proposed solution outperform each individual methods, and two other ensemble techniques.


assess the applicability of several time series forecasting models on real cloud workloads to support the development of dynamic resource allocation systems. 

A number of factors which must be considered in producing accurate forecasts are explored including the frequency
at which data is collected, the amount of data used to make a prediction, the model used to make predictions, and the number future values are predicted. The following forecasting models are evaluated for their ability to produce accurate predictions of real cloud workloads:


But performance will be affected when the peak load occurs. Conversely, leasing more virtual resources leads to a performance improvement, but also bears a higher cost. Catering to the user Service Level Agreement (SLA) while still keeping costs low is challenging for service clouds primarily due to the frequent variation of
platform workloads. With such a problem there should be an universal method to predict the platform workload, and then virtual resources can be added and released depending on this predicted workload



The goal of this work is to assess the applicability of several time series forecasting models on real cloud workloads to support the development of dynamic resource allocation systems
\usepackage{multirow}

\subsection{Challenges}
