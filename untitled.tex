\textbf\section{{Adaptive Online Prediction Technique for Workload prediction in PaaS systems}}


Workload prediction 
As described in the <<FIRST>> chapter, to avoid the drawbacks of threshold based reactive systems a proactive scaling algorithm should be run on top of the predicted future workload values. our proactive scaling solution has 3 major components
Workload Predictor - Predicting the workload for future time horizon
Scaling decision maker- Calculating the number of virtual machines required to handle the predicted workload while minimizing the cost of the scaling action.
Cost optimizer - Performing further cost optimizations like smart killing

Challenges
We have identified several challenges specific to workload prediction in a PaaS platforms.
PaaS system can have different applications with different workload characteristics, so that the workload predictor should not be overfitted to a specific workload pattern.
Workload predictive algorithm should be evolved and continuously learn the workload characteristics . 
Workload predictor should be able to give results within a bounded time period.
Give that the  time horizon for the prediction should be chosen based on the constraints like VM uptime and gracefully shutting down time, predictor should be able to give sufficiently accurate results.
Existing Works
There is a significant amount of already established research work in the workload prediction domain. Exponential smoothing is popularly used for predicting purposes. Mi et al. [18] also used a quadratic exponential smoothing against real workload traces (World Cup 98), and showed good accurate results, with a small amount of error. The auto-regression method has been widely used in the literature ([19], [20], [21]). Kupferman et al. [19] applied autoregression of single order to predict request rate and found that its performance depends largely on several user-defined parameters: the size of the input window and the size of the horizon window.Auto-regressive moving average method (ARMA) is the dominant time series analysis technique for workload and resource usage prediction. Roy et al. [4] use a second order ARMA for workload prediction on the World Cup 98 traces and showed good accurate results. Machine learning techniques like neural networks and regression have been applied by several authors but those techniques are not widely used as time series methods. There were researches on using history window values as the input for a neural network [22] and a multiple linear regression equation [19], [22]. The accuracy of both methods depends on the input window size.


Limitations of the existing research works
 These research works were primarily based on specific datasets. So that the resulted predictive model might not be a good fit for an application with different workload characteristics. In some of the solutions the predictive model was found using offline training on datasets so that the dynamic adaptation for the current workload changes is not there. 
In mathematically some time series prediction techniques like exponential moving average and ARIMA has some preconditions to be fitted well with the dataset. It’s quite unlikely that all the applications will met these preconditions. Even in a single prediction technique, there are parameters to be adjusted to fit with specific data set. So identifying optimum parameters for the model should be happend dynamic online training process rather than having constants defined in offline training process.

Prediction horizon

Prediction Horizon
Another interesting point in workload prediction is estimating the prediction interval, r. Islam et al. [22] proposed using a 12-minute interval, because the set-up time of VM instances in the cloud was typically around 5-15 minutes by that time. Time-series forecasting can be combined with reactive techniques. Iqbal et al. [23] proposed a hybrid scaling technique that utilizes reactive rules for scaling up (based on CPU usage) and a regression-based approach for scaling down.

Evaluation of the existing models
We have chosen 4 widely used prediction techniques in the literature (ARIMA, Neural network, Exponential Models and Naive prediction) and the existing workload prediction technique in Stratos. Then tested on several workloads <<DESCRIBE THOSE LOADS>> and saw that the some prediction technique performs well in some workload patterns while other technique perform well in different workloads.
For evaluation purpose we have used forecast package in R << DETAILS ABOUT THE PACKAGE>>. In that library there are time series datasets in different domains with typical patterns like trends, cycles and seasonality factors. In this analysis we wanted to qualitatively analyse the ability of each prediction technique to learn from current workload history and predict the time series while time series data is evolving periodically as what happen in autonomous autoscaler in operation. So that we have simulated online training scenario by streaming data points of the time series one at a time to each method and get the 1-step lookahead prediction and plotted against the real data points. Since the objective of this experiment to identify  how well an individual method can predict the future values by only considering the past history, we tried several publically available datasets in this package with predictable patterns even though they are not really related to the cloud workloads. The experimental results elaborated in <<IN SUB SECTION 1>>, are based on actual cloud workload datasets (CPU,Memory and Http Request in flight)  in which we  compare and contrast the performance of the proposed method vs existing methods. 
For this evaluation we have used the implementations of the Forecast pacakge[ID] . <<DESCRIPTON ABOUT THE IMPLEMENTATION>>>>
ARIMA: According to <<ROBIN>> auto.arima()  find out the best fitted ARIMA model and approximated the model coeffficents in by minimizing the error<<<BESPECIFIC >>> [https://www.otexts.org/fpp/8/7]

Ets: Model the data with best fitted exponential model [https://www.otexts.org/fpp/7/7]

	Nnetar: [https://www.otexts.org/fpp/9/3]

Dataset 1:
airmiles : The revenue passenger miles flown by commercial airlines in the United States for each year from 1937 to 1960.


Dataset 2:

Euretial: Quarterly retail trade index in the Euro area (17 countries), 1996-2011, covering wholesale and retail trade, and repair of motor vehicles and motorcycles. (Index: 2005 = 100).


Dataset 3: Annual oil production (millions of tonnes), Saudi Arabia, 1965-2010.




Dataset 4: Annual averages of the daily sunspot areas (in units of millionths of a hemisphere) for the full sun. Sunspots are magnetic regions that appear as dark spots on the surface of the sun. The Royal Greenwich Observatory compiled daily sunspot observations from May 1874 to 1976. Later data are from the US Air Force and the US National Oceanic and Atmospheric Administration.



Error Measures


For quantitative analysis, we used 2 types of  typical error measures 

Root Mean squared error which  not which is on the same scale as the data. since the RMSD is scale dependent, it cannot be used to make comparisons between series that are on different scales.[https://www.otexts.org/fpp/2/5]



Percentage errors have the advantage of being scale-independent, but it overlooked the errors for the small actual values.






Dataset
Arima
Exp
Nnet
Current
MSE
MAPE
MSE
MAPE
MSE
MAPE
MSE
MAPE
airline
1,412.9442
0.7207
1,370.4743
0.4352
2,400.5715
0.7184
1,377.0172
0.9246
sunspotarea
382.3602
1.3586
505.7503
1.1607
473.9241
0.4652
546.9379
0.9651
euretail
0.5244
0.0042
0.5755
0.0107
1.8821
0.0062
0.6503
0.0049
oil
55.3126
0.2508
54.9890
0.2508
51.6162
0.1595
61.8069
0.5846

The highlighted cell represents the minimum RMSE and MAPE. According to the results obtained, there is no an individual method which perform well in all the cases. Each method will fit the datasets which satisfies its assumptions well . If the conditions are not met, performance of some methods are below the average. For example neural network perform well on ‘oil’ dataset but perform worse in ‘euretail’.  Current stratos prediction method has the highest mean errors in almost all the cases.

major conclusions of this analysis that there is no single method which perform best in all the case. on the other hand a method which performs well in some dataset, might perform worst in another dataset.
Since an PaaS autonomous autoscaler should be able to expect any type of workload pattern, the prediction method should be able to give good enough estimates in average case while without without making a large error on specific patterns.

Idea of ensemble learning is quite frequently used in situations where there is no dominant technique which can provide the best results but can get good enough results from combining the results from several weak learners. In general forecasting domain we can see several models combining techniques  proposed in various researches [Combining time series models for forecasting], [Intelligent techniques for forecasting multiple time series in real-world systems ],
[Time series forecasting using a hybrid ARIMA and neural network model ].  

There are various views regarding model selection and combining multiple models. Some researches says combined methods improve the accuracy while some researches says it reduce the probability of getting larger errors than increasing the accuracy.According to the literature there are multiple ways of combining the individual results 
In the simple average, all models are assigned equal weights, i.e. wi=1⁄n (i=1, 2,..., n) [9, 10].
In the trimmed average, individual forecasts are combined by a simple arithmetic mean, excluding the worst performing k% of the models. A trimming of 10%–30% is usually recommended [9, 10].
In the Winsorized average, the i smallest and i largest forecasts are selected and respectively set as the (i+1)th smallest and (i+1)th largest forecasts [9].
In the median-based combining, the combination function f is the median of the individual forecasts. Median is sometimes preferred over simple average as it is less sensitive to extreme values [12, 13].
In the error-based combining, the weight to each model is assigned to be the inverse of the past forecast error (e.g. MSE, MAE, MAPE, etc.) of the corresponding model [3, 10].
In the variance-based method, the optimal weights are determined through the minimization of the total Sum of Squared Error (SSE) [7, 10].

Proposed Ensemble Prediction Method
In the median-based combining, the combination function f is the median of the individual forecasts. Median is 
sometimes preferred over simple average as it is less sensitive to extreme values [12, 13].
In the error-based combining, the weight to each model is assigned to be the inverse of the past forecast error (e
.g. MSE, MAE, MAPE, etc.) of the corresponding model [3, 10].
In the variance-based method, the optimal weights are determined through the minimization of the total Sum of 
Squared Error (SSE) [7, 10].
Proposed Ensemble Prediction Method
We are proposing an error based ensemble technique for workload prediction. As mentioned in <<subsection 1>>, 
offline training is not possible in this problem since the  workload history data may not be available at the 
beginning of the operation. While autoscaler in the operation workload history  is accumulated based on the user's 
workload requirement ( CPU, Memory, and Http request count). From the available dataset the prediction method 
should be able to predict for the future horizon. After the predictions, true values will be available in next time 
periods . So we accumulated latest real value to workload history and recalculate for the next forecast horizon. 
        
    In the existing error based combining techniques, Mean values of Absolute error, Absolute percentage error , 
squared error .. etc are taken into account when calculating the contribution from individual methods. 


We are proposing an error based ensemble technique for workload prediction. As mentioned in <<subsection 1>>, offline training is not possible in this problem since the  workload history data may not be available at the beginning of the operation. While autoscaler in the operation workload history  is accumulated based on the user's workload requirement ( CPU, Memory, and Http request count). From the available dataset the prediction method should be able to predict for the future horizon. After the predictions, true values will be available in next time periods . So we accumulated latest real value to workload history and recalculate for the next forecast horizon. 
		
	In the existing error based combining techniques, Mean values of Absolute error, Absolute percentage error , squared error .. etc are taken into account when calculating the contribution from individual methods. 






Experimental Results









[1]: Efficient Autoscaling in the Cloud using Predictive Models for Workload Forecasting
Nilabja Roy, Abhishek Dubey and Aniruddha Gokhale
 of EECS, Vanderbilt University, Nashville, TN 37235, USA
Email: {nilabjar,dabhishe,gokhale}@dre.vanderbilt.edu














Paper content

